<style>
  div {
      max-width: 600px;
      min-width: 100px;
  }
</style>

<!-- <div style="position: relative; width: 500px;"> -->
  <div style="position: absolute; top: 0; right: 0; width: 550px; text-align:right;">
    [English | <a href="../es/athina.html">Español</a>]
  </div>
  <!-- </div> -->

<div>
  <h1>Athina on iExec - Project Status</h1>
  <p></p>
</div>

<div id="milestonetwo">
  <h2>Milestone three: a payment model</h2>
  <p><b>Description:</b> Formulate a payment model for the future ecosystem.</p>
  <p><b>Status:</b> Completed [2018-09-29 Sat 19:16]</p>
  <p><b>Summary:</b> The future for dapp ecosystems is speculated
  upon. A couple of payment models are considered that might satisfy
  the needs of such ecosystem. A proof of principle example of one of
  such payment models is implemented for a simple case of a user query
  involving a dapp
  ensemble <a href="https://youtu.be/0I-HcOmZ_34?t=55">(video
  here)</a>. Finally, some feedback is provided.</p>

  <p><b>Mature dapp ecosystems, from the eyes of an AI assistant</b></p>

  <p>How will dapp ecosystems look like in the near future? We can
    expect a lot of dapps will be subsumed into AI assistants. These
    will likely work as combinations of functionality and data from
    different dapps, for the following reasons: First, blockchain will
    allow new types of economic incentives which will make even tiny
    collaborations between apps profitable. These incentives will
    unlock a new class of higher value applications, as heretofore
    siloed data and algorithms are combined profitably for the first
    time. Narrow data brings narrow AI, we can expect variegated data
    to produce more generally capable AI.
  </p>

  <p>Of course, narrow AI is becoming "wider" in part by virtue of
    better unsupervised learning models. It might seem old fashioned
    to suggest that the future of AI involves hand-engineered complex
    systems that combine functionality from different apps,
    decentralized or not. Why not have a single AI learn and do
    everything?</p>

  <p>Any AI, no matter how generally capable, (Turing-level and
    beyond), will always benefit from trading knowledge (data and
    algorithms) with other AIs and humans. Yes, our combined human +
    AI intelligence will grow, and a single AI will make thousands of
    jobs and apps obsolete. However, so will the amount of knowledge
    we produce grow, exponentially. There will always be expertise
    differentials among minds, we will always have a variety of
    problems of different nature that require collaboration. The
    greater the variety, the greater the need for integrative
    knowledge. A "Society of Mind"-like dapp ecosystem, as described,
    would incentivize the production of such integrative, high
    value-added knowledge.</p>

  <p>This sounds like a mature blockchain economy supporting a very
    large number of interactions between independent agents - and it
    could be blockchain's killer app.</p>

  <p> So, how might payments work? </p>

  <p><b>Payment models</b></p>

  <p> Simply put: Dapps should be able to arbitrarily hire other
    dapps. Upon receiving a query, a dapp should decide to either
    compute a response independently, or pay other dapps to help it
    complete the task.</p>

  <p>Let's take this hypothetical conversation for example:</p>

<table border="0" cellspacing="4" cellpadding="2">
<tr> 
     <td bgcolor="#000080">
        <table border="0" cellpadding="4" cellspacing="0">
        <tr><td bgcolor="#ffffff">
	    <p>Athina
	    [<b>pre-qa</b>, <b>my-interests</b>, <b>eu-legislation</b>]:
	    Hi, <a href="https://medium.com/@gijsnelissen/stop-complaining-about-gdpr-86e893f8d11">this new article might interest you.</a>. It involves new regulations regarding financial asset tokenizations in Europe.</p>
	    <p align="right">User: Thank you, could you summarize it?</p>
	    <p>Athina [<b>summarization</b>]: Sure, (…)</p>
	    <p align="right">User: Thank you. How was The Economist's response to these changes?</p>
	   <p>Athina [<b>sentiment-analysis</b>]: <a href="https://www.economist.com/news/briefing/21721634-how-it-shaping-up-data-giving-rise-new-economy">They are rather optimistic about their long term impact.</a>.</p>



</td>
        </tr></table></td>
     
</table>

  <p>In a mature dapp market, how might this look, in terms of interactions between dapps? The pre-qa dapp could consult the EU-law, my-interests, and summarization apps. The EU-law dapp in turn could make use of a translator dapp.</p>

  <pre>
                   +----------+         +------------+
                   |          +-------->+            |
                   |  EU-law  |         | translator |
                   |          +<--------+            |
                   +---+---+--+         +------------+
                       ^   |
                       |   v
+---------+        +---+---v--+         +--------------+
|         |        |          +<--------+              |
| Athina  +------->+  pre-qa  |         | my-interests |
|         |        |          +-------->+              |
+---------+        +---+---+--+         +--------------+
                       |   ^
                       v   |
                   +---+---+-------+
                   |               |
                   | summarization |
                   |               |
                   +---------------+

						     </pre>


  <p align="center">Fig. 1 Payments in the future: Any dapp can triage a query.</p>

  <p>This model involves decentralized triage. Any dapp can hire any
    other app to fulfill the query. This means that depending on the
    query, a dapp might require more or less resources (computational
    capacity, data and algorithms from other dapps) to fulfill
    it. It's important therefore that in the future, a dapp can charge
    different prices for different tasks. </p>

  <p>There will always be multiple ways to answer the same
  query. Market forces will ensure that the dapp ensembles with the
  highest predictive power / cost (RLC) will be more popular.</p>

  <p>The enabling technologies required to make this kind of interaction possible <a href="https://techcrunch.com/2017/09/18/ethereum-will-replace-visa-in-a-couple-of-years-says-founder/">are already underway.</a> From user query to response, the process should last less than approximately 5 seconds.</p>

  <p>Are practical applications impossible until then? No, some computational tasks can still be useful given large delays (eg. periodic training on new data, whereby you update your model parameters every week or month). Until then however, any query triage will have to be centralized, in an expert manager such as Athina.</p>

  <pre>
                      +------------+
             +------->+            |
             |        | translator |
             +<-------+            |
             |        +------------+
             |
             |        +----------+
             +------->+          |
             |        | EU-law   |       
             +<-------+          |
             |        +----------+
             |
+--------+   |        +----------+
|        |   +------->+          |
| Athina |---|        |  pre-qa  |
|        |   +<-------+          |
+--------+   |        +----------+
             |
             |        +---------------+
             +------->+               |
             |        | summarization |
             +<-------+               |
             |        +---------------+
             |
             |        +--------------+
             +------->+              |
             |        | my-interests |
             +<-------+              |
                      +--------------+

    </pre>


  <p align="center">Fig. 2 Payments in the short term: an expert
  manager triages queries.</p>
  <!-- notes: there will be incentive to build in athina -->
  <p>Until then, the interactions and payments fall entirely upon
  "expert managers" such as Athina. They will have to decide which
  combinations of dapps to use for different tasks. There will still
  be an incentive to combine data and algorithms from different dapps,
  since connected knowledge tends to be more valuable. This is more
  inefficient however, and will be a bottleneck until Ethereum scales,
  as mentioned previously.</p>

  <p>On the other hand, this will allow a more curated experience,
  akin to the closed model of the first iPhone (which was not open to
  third party developers). This is not a bad way to start.</p>

  <p>A proof of principle example of this model is provided. In this
  example, the user has an intent that Athina classifies as "typograph
  Cervantes" (see Milestone 2 to see how DialogFlow facilitates this),
  which is an "ensemble intent" because it requires two dapps:
  Cervantes, to improvise some prose, and Typographer, to typeset that
  prose into a beautiful, old style document. In this example, the
  "End user" (address 0x5f3fdff7d42333aa276e31ba658718b702d69684)
  launches ensemble task with intent "typograph Cervantes", which
  automatically sends payment to owners of both apps involved,
  Cervantes (wallet address
  0x84eddc455b224b5233b633fab74731117846cf19) and Typographer (wallet
  address
  0x5b309b5c144b68a44f5d5a8fe2ef7428b2e4e9ee). <a href="https://youtu.be/0I-HcOmZ_34?t=55">Here
  is a video of this process.</a>


  <p><b>Feedback</b></p>

  <p>In my personal order of importance:</p>
  <ul>
    <li>Allow dapps to charge different amounts depending on task/user
    intent, to allow decentralized triage (as described above) in the future.</li>
    <li>In the short term, make it easy to compare costs of computational tasks in iExec vs. costs in platforms like AWS. I would like to use iExec for all my non-urgent neural net training tasks.</li>
    <li>Intellectual property / code protection (I've been told work is underway with SGX technology, this is very important for us.)</li>
    <li>More documentation for the JS interface would be very welcome.</li>
    <li>Removal of wall-time limits</li>
    <li>More documentation on how to set up your own worker, for easier, independent experimentation.</li>
  </ul>

    <p><b>Conclusion</b>New payment models from decentralized dapp markets will allow a new class of higher value machine learning applications, which will tend to take the form of cybernetic assistants. It will be important that any dapp can hire any other dapp and so be able to charge differently for each type of query. Until the enabling technologies (ie. a VISA-scale Ethereum) are ready, expert managers will have to manually curate combinations of data and algorithms from different dapps, as in the early days of the iPhone app platform.</p>


<div id="milestonetwo">
  <h2>Milestone two: an ensemble of dapp agents</h2>
  <p><b>Description:</b> Build at least one more agent which would work with the first one in an ensemble fashion.</p>
  <p><b>Status:</b> Completed [2018-06-13 Wed]</p>
  <p><b>Summary:</b> An ensemble implemented using a combination of
    Dialogflow and an intermediary service which calls iExec apps to
    satisfy user needs. You can talk to it on Facebook Messenger, Slack,
    Viber, Twitter, Twilio IP, Twilio Text Messaging, Skype, Topo,
    Telegram, Kik, LINE, Cisco Spark, Amazon Alexa, and Microsoft
    Cortana. You can use voice or text. You can also chat with
    it <a href="https://bot.dialogflow.com/acd6075f-7c5a-4766-adb5-48a8fde85265">at
      this web demo page</a></p>
  <p>The Athina ensemble works with two iExec apps: the app from Milestone 1 (TinyChat) and a second iExec app agent, "Improvising Cervantes", which has been completed and improved.</p>
  <p><b>Usage:</b>
    Dialogflow has a 5 second timeout. Ethereum and iExec will become faster, but right now interactions have to be asynchronous. For "Improvising Cervantes", imagine you're asking the Spanish author Miguel de Cervantes to write you a little improvised prose. He accepts, but he needs a few minutes. To do this, <a href="https://bot.dialogflow.com/acd6075f-7c5a-4766-adb5-48a8fde85265">go here and</a> tell Athina any of the following:
    <ul style="list-style-type:disc">
      <li>Write something for me, Mike</li>
      <li>What are you thinking about, Miguel?</li>
      <li>Hi Mike, write me some prose</li>
      <li>Miguel, could you write me something?</li>
    </ul>
    Similar sentences will have the same effect. Dialogflow will launch a webhook to the intermediary service which fills an open iExec order to complete the job. Give Miguel a few minutes, and to check on his progress, you can ask him:
    <ul style="list-style-type:disc">
      <li>Are you finished?</li>
      <li>Are you done?</li>
      <li>Send me what you wrote.</li>
      <li>Send me the prose.</li>
    </ul>
    Again, any similar sentence will be understood. Miguel will tell you if he needs more time, and if he's done, he will send you his improvised prose.
  <p>
    Likewise to send a message to the TinyChat app on iExec, you can say:
    <ul style="list-style-type:disc">
      <li>tinychat how is it going?</li>
      <li>tinychat how are you?</li>
      <li>tinychat hello</li>
      <li>tinychat what are you thinking about?</li>
    </ul>
    You will also have to wait. To check TinyChat's response, write or speak:
    <ul style="list-style-type:disc">
      <li>tinychat what is your response?</li>
      <li>tinychat what is your reply?</li>
      <li>tinychat tell me what you think</li>
      <li>tinychat what is your answer?</li>
      <li>tinychat give me your response</li>
    </ul>
    And you will receive its response when it's done.
  </p>
  </p>
  <p><b>Current issues:</b>
    The following issues have been raised with the good people at #beta-testers:
    <ul style="list-style-type:disc">
      <li>The path issue with Dockerized apps is back: In Tinychat, /iexec/oneturn.py once again doesn't work (even though it works fine when run directly as a Docker app. This issue was present in V1 and was solved, but it's back now. I notified Francois about it.</li>
      <li>The result file combines stderr and stdout: They used to be separate. In Cervantes, the response produced will include stderr before the improvised prose.</li>
      <li>Sell orders are available intermittently, sometimes in category 3, sometimes in category 4.</li>
      <li>Jobs sometimes take a very, very long time complete.</li>
    </ul>
  </p>
  <p><b>Conclusion:</b>
    In the near future, I can see practical applications of iExec resources because my apps will have some non-urgent computational needs, eg. train models in the background and be happy with a one-week delay in results. I expect prices to be good so I see a real practical advantage.</p>
  <p>To move in that direction I need to know how to run proprietary code in Docker images, code that only I would be able to see. Any suggestions in this regard are welcome, I'm sure it's feasible.<p/>

  <p>In the future, I see us developing conversational apps for Athina and using iExec resources whenever it's cheaper, or whenever combinations of dapps are necessary to accomplish some task, as combinations of dapps will benefit from microtransaction economics (as described in the proposal).</p>
</div>


<div id="milestoneone">
  <h2> Milestone one: a simple chatbot</h2>
  <p><b>Description:</b> Build a basic NLP agent running on iExec computational resources.</p>
  <p><b>Status:</b> Completed [2018-03-09 Fri]</p>
  <p><b>Summary:</b> A basic neural dialogue agent, employing a sequence to sequence model, has been trained, added to docker image javiermares/tiny-chat, and deployed to the iExec network.</p>
  <p>As the first component of milestone two, a second agent has also been deployed: a character level model which improvises prose in the style of Cervantes. This is the first model fine-tuned for this task, to the knowledge of the author.
  <p>We want to show the unique capabilities of iExec and blockchain, like fine grained collaboration between dapps. As a first step in that direction, one illustrative idea could be to use the improvised prose from the Cervantes app as an input to a neural calligraphy generator, so it looks like a handwritten note from Cervantes. Other similar ideas are being worked on.</p>

  <p><b>Dapps</b><p>
  <p>Improvising Cervantes v0.04 - iexec submit 'python3 /examples/nlp/dime_algo.py' --dapp 0x25412143e4c5392dea108c2834008985507410f2</p>
  <p>Tiny Chat v0.03 - iexec submit 'python /iexec/oneturn.py how are you' --dapp 0x2e785496d4f66BF1e2dDFba1a7755eb2EbF75d2C</p>
  
  <p><b>Comments:</b><p>
  <p>UPDATE [2018-04-11 Wed]: Francois mentioned that iExec has a bug whereby it won't find scripts located in the Docker image's root directory (eg. iexec submit 'python oneturn.py' --dapp would be incapable of finding oneturn.py. As a temporary measure, the script is now at /iexec/oneturn.py instead.</p>
  <p>Now iExec can find the script, but the script itself is unable to find filenames. This is an iExec bug, as this doesn't happen when running the command in Docker (eg.  docker run javiermares/tiny-chat python /iexec/oneturn.py hey dude). <a href="https://iexec-team.slack.com/archives/C3Y0MJN8Y/p1523411097000034">The slack discussion can be found here.</a></p>

  <p>"Bridge Failed" iExec bug [2018-03-09 Fri]. There seems to be an issue on iExec with the cmdline variable. It works fine for a command like 'python3 /examples/nlp/dime_algo.py', but the longer command associated with the Tiny Chat dapp produced a "Bridge Failed" error. The command is 'iexec submit 'python oneturn.py hello' --dapp 0x2e785496d4f66BF1e2dDFba1a7755eb2EbF75d2C' where 'hello' represents the user input string. It works on the associated docker image, javiermares/tiny-chat. This error has been raised in the beta-testers slack channel and Francois mentioned it will be looked at on Monday.</p>

  <p></p>
</div>
